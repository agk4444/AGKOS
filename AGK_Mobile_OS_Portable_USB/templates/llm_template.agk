# AGK LLM Template - AI-Powered Application
# This template demonstrates how to integrate Large Language Models into your AGK applications
# Perfect for: AI assistants, code generators, content creators, educational tools

import llm
import io
import logging

# Global configuration
define constant API_KEY as String = "your-api-key-here"
define constant DEFAULT_MODEL as String = llm.gpt4()

# Main application entry point
define function main:
    # Initialize logging for the AI application
    create logger as Logger
    set logger to logging.get_logger("AI_Assistant")
    logging.set_level(logger, logging.INFO)
    logging.add_console_handler(logger)

    logging.info(logger, "Starting AI Assistant Application")

    # Initialize LLM client
    create ai_client as LLMClient
    set ai_client to llm.create_llm_client(API_KEY, DEFAULT_MODEL)

    # Configure AI client settings
    llm.set_temperature(ai_client, 0.7)
    llm.set_max_tokens(ai_client, 2000)

    # Enable response caching for better performance
    llm.enable_response_cache("openai", 300.0)  # Cache for 5 minutes

    logging.info(logger, "AI client initialized and configured")

    # Run the main application loop
    run_application_loop(ai_client, logger)

# Main application loop with menu-driven interface
define function run_application_loop that takes ai_client as LLMClient, logger as Logger:
    create running as Boolean
    set running to true

    while running:
        io.println("\nü§ñ AI Assistant - Choose an option:")
        io.println("1. Code Generation")
        io.println("2. Code Explanation")
        io.println("3. Text Summarization")
        io.println("4. Language Translation")
        io.println("5. Conversation Mode")
        io.println("6. AI-Powered Code Review")
        io.println("7. Creative Writing Assistant")
        io.println("8. View Cache Statistics")
        io.println("9. Exit")
        io.print("Enter your choice (1-9): ")

        create choice as String
        set choice to io.read_line()

        if choice == "1":
            handle_code_generation(ai_client, logger)
        else if choice == "2":
            handle_code_explanation(ai_client, logger)
        else if choice == "3":
            handle_text_summarization(ai_client, logger)
        else if choice == "4":
            handle_language_translation(ai_client, logger)
        else if choice == "5":
            handle_conversation_mode(ai_client, logger)
        else if choice == "6":
            handle_code_review(ai_client, logger)
        else if choice == "7":
            handle_creative_writing(ai_client, logger)
        else if choice == "8":
            display_cache_statistics(ai_client, logger)
        else if choice == "9":
            set running to false
            logging.info(logger, "Application shutting down")
        else:
            io.println("‚ùå Invalid choice. Please try again.")

# Code generation functionality
define function handle_code_generation that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüíª Code Generation Assistant")
    io.print("Describe what you want to build: ")
    create description as String
    set description to io.read_line()

    io.print("Programming language: ")
    create language as String
    set language to io.read_line()

    create timer as Timer
    set timer to logging.start_timer(logger, "code_generation")

    create generated_code as String
    set generated_code to llm.generate_code(ai_client, description, language)

    logging.end_timer(timer)

    io.println("\nüìù Generated Code:")
    io.println("‚îÄ" * 50)
    io.println(generated_code)
    io.println("‚îÄ" * 50)

    logging.info(logger, "Code generation completed for: " + description)

# Code explanation functionality
define function handle_code_explanation that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüîç Code Explanation Assistant")
    io.print("Paste your code here (press Enter twice to finish):\n")

    create code_lines as List
    create line as String

    while true:
        set line to io.read_line()
        if line == "":
            break
        add line to code_lines

    # Join lines back into code
    create code as String
    set code to ""
    for each line in code_lines:
        set code to code + line + "\n"

    if code != "":
        create timer as Timer
        set timer to logging.start_timer(logger, "code_explanation")

        create explanation as String
        set explanation to llm.explain_code(ai_client, code)

        logging.end_timer(timer)

        io.println("\nüìñ Code Explanation:")
        io.println("‚îÄ" * 50)
        io.println(explanation)
        io.println("‚îÄ" * 50)

        logging.info(logger, "Code explanation completed")

# Text summarization functionality
define function handle_text_summarization that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüìÑ Text Summarization Assistant")
    io.print("Paste your text here (press Enter twice to finish):\n")

    create text_lines as List
    create line as String

    while true:
        set line to io.read_line()
        if line == "":
            break
        add line to text_lines

    create text as String
    set text to ""
    for each line in text_lines:
        set text to text + line + "\n"

    if text != "":
        create timer as Timer
        set timer to logging.start_timer(logger, "text_summarization")

        create summary as String
        set summary to llm.summarize_text(ai_client, text)

        logging.end_timer(timer)

        io.println("\nüìã Summary:")
        io.println("‚îÄ" * 50)
        io.println(summary)
        io.println("‚îÄ" * 50)

        logging.info(logger, "Text summarization completed")

# Language translation functionality
define function handle_language_translation that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüåê Language Translation Assistant")
    io.print("Enter text to translate: ")
    create text as String
    set text to io.read_line()

    io.print("Target language (e.g., Spanish, French, German, Japanese): ")
    create target_lang as String
    set target_lang to io.read_line()

    create timer as Timer
    set timer to logging.start_timer(logger, "translation")

    create translation as String
    set translation to llm.translate_text(ai_client, text, target_lang)

    logging.end_timer(timer)

    io.println("\nüî§ Translation:")
    io.println("‚îÄ" * 50)
    io.println(translation)
    io.println("‚îÄ" * 50)

    logging.info(logger, "Translation completed: " + target_lang)

# Interactive conversation mode
define function handle_conversation_mode that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüí¨ Interactive Conversation Mode")
    io.println("Start chatting with the AI (type 'exit' to quit)")

    create conversation as Conversation
    set conversation to llm.start_conversation(ai_client)

    create user_input as String
    create ai_response as String

    while true:
        io.print("\nYou: ")
        set user_input to io.read_line()

        if user_input == "exit":
            break

        llm.add_user_message(conversation, user_input)

        create timer as Timer
        set timer to logging.start_timer(logger, "conversation_response")

        set ai_response to llm.get_response(conversation)

        logging.end_timer(timer)

        io.println("AI: " + ai_response)

        llm.add_assistant_message(conversation, ai_response)

        logging.info(logger, "Conversation turn completed")

# AI-powered code review
define function handle_code_review that takes ai_client as LLMClient, logger as Logger:
    io.println("\nüîß AI Code Review Assistant")
    io.print("Paste your code for review (press Enter twice to finish):\n")

    create code_lines as List
    create line as String

    while true:
        set line to io.read_line()
        if line == "":
            break
        add line to code_lines

    create code as String
    set code to ""
    for each line in code_lines:
        set code to code + line + "\n"

    if code != "":
        create review_prompt as String
        set review_prompt to "Please review the following code for best practices, potential bugs, performance issues, and suggest improvements:\n\n" + code

        create timer as Timer
        set timer to logging.start_timer(logger, "code_review")

        create review as String
        set review to llm.ask_llm(ai_client, review_prompt)

        logging.end_timer(timer)

        io.println("\nüìã Code Review:")
        io.println("‚îÄ" * 50)
        io.println(review)
        io.println("‚îÄ" * 50)

        logging.info(logger, "Code review completed")

# Creative writing assistant
define function handle_creative_writing that takes ai_client as LLMClient, logger as Logger:
    io.println("\n‚úçÔ∏è Creative Writing Assistant")
    io.print("What would you like help writing? (story, poem, article, etc.): ")
    create writing_type as String
    set writing_type to io.read_line()

    io.print("Provide details or topic: ")
    create details as String
    set details to io.read_line()

    create writing_prompt as String
    set writing_prompt to "Please write a " + writing_type + " about: " + details + "\n\nMake it engaging and well-structured."

    create timer as Timer
    set timer to logging.start_timer(logger, "creative_writing")

    create writing as String
    set writing to llm.ask_llm(ai_client, writing_prompt)

    logging.end_timer(timer)

    io.println("\nüìù Creative Writing:")
    io.println("‚îÄ" * 50)
    io.println(writing)
    io.println("‚îÄ" * 50)

    logging.info(logger, "Creative writing completed: " + writing_type)

# Display cache statistics
define function display_cache_statistics that takes ai_client as LLMClient, logger as Logger:
    create stats as Object
    set stats to llm.get_cache_statistics("openai")

    io.println("\nüìä Cache Statistics:")
    io.println("‚îÄ" * 30)
    io.println("Cache stats: " + stats)
    io.println("‚îÄ" * 30)

    logging.info(logger, "Cache statistics displayed")

# Error handling and retry functionality
define function handle_api_error that takes logger as Logger:
    create error as APIError
    set error to llm.get_last_api_error()

    logging.error(logger, "API Error occurred: " + error)

    io.println("‚ùå An API error occurred. Would you like to retry? (y/n): ")
    create retry_choice as String
    set retry_choice to io.read_line()

    if retry_choice == "y":
        io.println("üîÑ Retrying last request...")
        # Note: In a real implementation, you'd pass the client here
        logging.info(logger, "User requested retry")

# Utility function to clear cache if needed
define function clear_cache_if_needed that takes ai_client as LLMClient:
    io.println("üóëÔ∏è Cache cleared to ensure fresh responses")
    llm.clear_response_cache("openai")

# Initialize the application
main()